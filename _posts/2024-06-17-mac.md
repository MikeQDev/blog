---
layout: post
title:  "Modernizing a Fortune 500's monitoring, with code"
categories: Platform
tags: Platform Monitoring APM Terraform IaC MaC
author: Mike
---

After 5 years of ClickOps in our vendors APM tool, we've finally broke the mold

<!-- In January 2024 I joined a brand new platform team that had a focus on SRE. After brainstorming a few potential projects to tackle, our team and management unanimously decided that improving our organization's APM practice was a top priority. This decision was made based on the disheartening amount of production downtime and missed performance OKRs, especially for "tier-1 services" (this company is in the insurance industry, BTW) -->

<!-- Most of the organization's production incidents were brought to our attention through customer complaints. It was clear that engineering teams needed to be empowered with a more proactive monitoring and alerting approach -->

<!-- These operational flaws stemmed primarily from a couple of things -- complex bugs in the code, poor observability standards and practices (the next item on our teams roadmap), and uncommunicated changes with dependencies. But there's a deeper issue: almost each time an incident was identified, it was due to customer complaints -->

# The existing configuration process

## ClickOps

<!-- We have two environments for our APM backend: NONPROD and PROD -->

If a product team needed monitoring and alerts configured for their service, they'd have two options:

1. Submit a ticket for a performance engineer to manually configure their monitoring and alerting
1. Request temporary 24-hour admin access to the APM tool to configure their monitor and alerting

Ticketing systems didn't scale great in this situation. Security concerns of handing out admin access, and human error that the above approaches introduced, there's also lack of consistency across environments as well as reusability across services

Each time a team needed their service configured, similar ClickOps would occur, often with slight variations (intentional or not). What made me squirm even more was comparing a service's NONPROD to PROD configurations and seeing numerous inconsistencies between the environments

## Maturing slightly: API calls

If life gave clever engineers 24-hour admin access to a toilsome process/tool, they'd generate non-expiring admin API tokens. *Hypothetically speaking.*

A couple of folks had *consentually* obtained API tokens from the tooling owners and created private Postman collections they created on the side of their desks. This allowed these users to easily configure the APM backend by changing a few variables then pressing the "Send" button to emit the API request

This kind of worked, but fell short in a couple of areas (list not exhaustive):

1. No guardrails, governance, or rollback process
1. Maintaining a bunch of Postman collections for each configuration was tedious
1. No state management or API request idempotency
1. Not self-service for engineering teams
1. Could not be publicized/offered as a service within the company

In a sense, this felt like a form of shadow IT, ran by a limited number of clever users with a privileged API token

We could do better

# Pushing for change

# The push(back) for change
Architects. Monaco (but yaml, reliant on another vendor tool, new tech review + approval), TF. "Build an API with API calls with some DB"
  On a 2-week vacation during this
"Use the vendors YAML config tool"
"Emotional" struggles
  We are not the tooling team. We are platform team with a focus on SRE looking to get the best use out of our vendor tool

# The new process
Can't use TFE VCS due to audit reasons. Change ticket. Just go with the company's engineering portal that generates a TF pipeline for us

## The ideal approach

# Architecture

Our team designed a modernized approach for managing our APM solution using two flows:

## Decentralized, "engineer enablement"

The objective was to enable engineers to self-service their APM configurations with as little intervention as possible

This entailed offering limited-privilege API tokens that would be shared at the organization level (for simplicity. Sharing the token at team or service level was also an option, but rolling out an initial solution was higher priority)

This API token would be stored in a secret store, accessible by authorized consumers such as Jenkins and GitHub Action pipelines. The APM's Terraform provider would be initialized with this token for authentication at Terraform's `plan` and `apply` stages

### Projects lacking Terraform

If an applications pipeline didn't have Terraform (e.g.: apps deployed by ArgoCD to K8s), rather than create a new TF state/workspace and add a new pipeline step in each of these repos, we recommended these apps deploy their APM configs via a shared, centralized repo as well. The shared, centralized repos pipeline would've used an API token with similar privileges to the "engineer enablement" token, however, to avoid consumer confusion and skip the need for additional TF workspaces, we recommended these configurations merge into the organizations centralized, admin enablement repo

## Centralized, "admin enablement"

We also needed a way to perform operations against the APM product that were more privileged than what the engineer enablement API token granted. Governance and approval was needed for the safety of our environment when performing these operations

Our initial thought was to have an entire centralized repo for the entire company with a directory/module for each organization, but the likelihood of someone breaking the build for the rest of the company was too much of a concern

Instead, we decided that each organization would have their own "&lt;RedactedAPMProductName&gt;-Terraform-config" repo and corresponding TF workspace

We scaffold our organizations PoC repo by "value streams" which were broken down further by domains (or teams in some cases)

Example structure:
```
valueStreamA/
  domainA/
  domainB/
    subDomainY/
valueStreamB/
  domainC/
  domainD/
    someConfigs.tf
shared/
  configsSharedAcrossValueStreams/
```

### Approvals

Rather than having a few approvers for an organization being overwhelmed with approving *all* of the PRs for config changes, we used `CODEOWNERS` files to desginated approvers ("APM champions/SMEs") for each value stream. Of course, `CODEOWNERS`

For configurations that required even more permissions, or were shared across the company (i.e.: not constrained to a single organization), this similar centralized/shared repo pattern was replicated at the enterprise level. The owners/approvers of this repo were the company's gatekeepers of the APM tool. Governing these configs at the enterprise level with proper approvals ensured that super-superuser operations were authorized and that company-shared configs weren't accidentally tampered with



 they'd perform a handful of steps:

1. Firewall request
1. Ticket request to configure monitoring backend tol 

NONPROD then PROD. Inconsistencies

Not even "what good looks like"

## Challenges

2 environments: NONPROD and PROD
  What about staging?
  branches. folder-basd. env-map

Secrets management

## Rollout

- Documentation/README
- Pull Request template -- ignored
- Dog fooding with junior engineers
- Pilot teams
- Complex use cases

### OK but not great adoption
Copy-pastable example configs
Eng's difficult to grasp because they didn't know TF
- modules, but too much maintenance. Leaky abstraction. PoC stage, get something working before investing in a perfect solution

## Solution: CodeGen
- "Gold standard" code generation
- "Deployed an EKS app to dev, set up alerting". EKS namespace, email for alerts (Teams webhooks were being sunset for an unwieldy webhook process). Baseline with company-configured default service anomaly detection
- 4-6 hours down to 5 minutes

## The big fail
Alerts off-the-hook
Remediation. Should've had audit log


### Earning back trust

# Concerns
- Locked in deeper with vendor
- Poor vendor IAM, blast radius

* content
{:toc}
